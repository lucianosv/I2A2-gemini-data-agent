# app.py

import os
import io
import pandas as pd
import streamlit as st
from agent import (
    initialize_gemini_api,
    classify_intent,
    get_analysis_code,
    get_chat_response,
    execute_code,
)

# ---------------- Configura√ß√£o da p√°gina ----------------
st.set_page_config(page_title="Agente de An√°lise de Dados", page_icon="üìä", layout="wide")

# ---------------- Estado da sess√£o ----------------
st.session_state.setdefault("df", None)
st.session_state.setdefault("file_meta", None) # (name, size)
st.session_state.setdefault("sample_rendered", False) # controla render da amostra
st.session_state.setdefault("chat_history", [])
st.session_state.setdefault("insights", []) # mem√≥ria de conclus√µes

# ---------------- Chave de API ----------------
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    st.error("A chave de API do Gemini n√£o foi encontrada. Configure a vari√°vel de ambiente 'GEMINI_API_KEY'.")
    st.stop()
else:
    initialize_gemini_api(api_key)

# ---------------- UI ----------------
st.title("üé≤ Gemini Data Agent")
st.markdown("Fa√ßa o upload de um arquivo CSV e comece a conversar com o agente de IA.")

# Upload
uploaded_file = st.file_uploader("Escolha um arquivo CSV", type=["csv"])

# Detecta mudan√ßa de arquivo com metadados est√°veis
def get_meta(f):
    if f is None:
        return None
    try:
        size = f.size
    except Exception:
        try:
            size = len(f.getbuffer())
        except Exception:
            size = None
    return (f.name, size)

new_meta = get_meta(uploaded_file)

if uploaded_file is not None:
    if st.session_state.file_meta != new_meta:
        # Novo arquivo: carrega df, reseta amostra e d√° boas-vindas
        try:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file)
            st.session_state.df = df
            st.session_state.file_meta = new_meta
            st.session_state.sample_rendered = False
            st.session_state.chat_history = [
                {"role": "assistant", "content": "Arquivo recebido! Pronto para analisar. Fa√ßa uma pergunta ou pe√ßa um gr√°fico."}
            ]
            st.session_state.insights = [] # reinicia mem√≥ria para novo conjunto
        except Exception as e:
            st.error(f"Falha ao ler CSV: {e}")
            st.stop()
else:
    st.info("Envie um CSV para come√ßar.")
    st.stop()

# Layout principal
#left, right = st.columns([2, 1])

#with left:
st.subheader("Amostra do DataFrame")
sample_box = st.empty()

if st.session_state.df is not None and not st.session_state.sample_rendered:
    sample_box.dataframe(st.session_state.df.head(10)) # primeira renderiza√ß√£o
    st.session_state.sample_rendered = True
elif st.session_state.sample_rendered:
    # Mant√©m a amostra vis√≠vel entre reruns
    sample_box.dataframe(st.session_state.df.head(10))

#with right:
st.subheader("Mem√≥ria de conclus√µes")
if st.session_state.insights:
    for i, ins in enumerate(st.session_state.insights, 1):
        st.markdown(f"- {ins}")
else:
    st.caption("Sem conclus√µes registradas ainda. Pe√ßa an√°lises e gr√°ficos.")

# Hist√≥rico de chat (render sempre o que j√° existe)
st.subheader("Conversa")
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Entrada do usu√°rio
user_input = st.chat_input("Digite sua pergunta (ex.: 'fa√ßa um histograma de Amount' ou 'quais conclus√µes at√© agora?').")

def push_assistant(text: str):
    st.session_state.chat_history.append({"role": "assistant", "content": text})
    with st.chat_message("assistant"):
        st.markdown(text)

if user_input:
    # 1) Adiciona e exibe imediatamente a pergunta do usu√°rio
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # 2) Comandos de conclus√µes r√°pidas
    normalized = user_input.strip().lower()
    if normalized in {
        "conclusoes", "conclus√µes", "resumo", "insights",
        "quais conclusoes", "quais conclus√µes at√© agora?",
        "quais conclus√µes at√© agora"
    }:
        if st.session_state.insights:
            bullets = "\n".join([f"- {i}" for i in st.session_state.insights])
            push_assistant(f"Aqui est√£o as conclus√µes registradas at√© agora:\n\n{bullets}")
        else:
            push_assistant("Ainda n√£o h√° conclus√µes registradas. Solicite alguma an√°lise ou gr√°fico para come√ßarmos.")
        st.stop()
    
    # 3) Classifica√ß√£o de inten√ß√£o
    intent = classify_intent(user_input)
    if intent not in {"analysis", "chat"}:
        push_assistant("N√£o consegui entender a inten√ß√£o. Reformule pedindo uma an√°lise dos dados ou continue a conversa.")
        st.stop()
    
    # 4) Roteamento
    if intent == "chat":
        reply = get_chat_response(user_input)
        push_assistant(reply)
        st.stop()
    
    # intent == "analysis"
    df = st.session_state.df
    sample_text = df.head(20).to_markdown(index=False)
    code = get_analysis_code(user_input, sample_text)
    
    # --- Corre√ß√£o autom√°tica de linhas INSIGHT sem print() ---
    fixed_lines = []
    for line in code.splitlines():
        if line.strip().startswith("INSIGHT:"):
            insight_txt = line.strip().replace('"', "'")
            fixed_lines.append(f'print("{insight_txt}")')
        else:
            fixed_lines.append(line)
    code = "\n".join(fixed_lines)
    
    # Exibe o c√≥digo gerado
    with st.expander("C√≥digo gerado pela IA", expanded=False):
        st.code(code, language="python")
    
    # Executa o c√≥digo e captura sa√≠da/erros
    stdout_text, error_text = execute_code(code, df)
    
    if error_text:
        push_assistant(f"Ocorreu um erro na execu√ß√£o:\n\n``````")
        st.stop()
    
    # Exibe resultados textuais, se houver
    if stdout_text.strip():
        with st.chat_message("assistant"):
            st.markdown("Resultado da an√°lise:")
            st.code(stdout_text)
        
        # Registra uma nota no hist√≥rico textual para indicar que houve sa√≠da/gr√°ficos
        st.session_state.chat_history.append({
            "role": "assistant",
            "content": "Resultado da an√°lise exibido e gr√°ficos renderizados acima."
        })
        
        # CORRE√á√ÉO APLICADA: Melhor extra√ß√£o e registro de INSIGHT
        new_insights = []
        for line in stdout_text.splitlines():
            line_stripped = line.strip()
            # Verifica se a linha cont√©m INSIGHT (case-insensitive)
            if line_stripped.upper().startswith("INSIGHT:") or "INSIGHT:" in line_stripped.upper():
                # Extrai o texto ap√≥s INSIGHT:
                if ":" in line_stripped:
                    insight = line_stripped.split(":", 1)[1].strip()
                    if insight:  # s√≥ adiciona se n√£o est√° vazio
                        new_insights.append(insight)
                        # Debug: mostra que o insight foi encontrado
                        st.write(f"üîç Debug: Insight encontrado: '{insight}'")
        
        # Adiciona os insights encontrados √† mem√≥ria
        if new_insights:
            st.session_state.insights.extend(new_insights)
            insight_count = len(new_insights)
            plural = "conclus√£o" if insight_count == 1 else "conclus√µes"
            push_assistant(f"‚úÖ {insight_count} {plural} registrada(s) na mem√≥ria!")
        else:
            # Debug: mostra quando nenhum insight foi encontrado
            st.write("üîç Debug: Nenhum insight encontrado no output")
            # Ainda assim confirma execu√ß√£o
            push_assistant("An√°lise executada com sucesso.")